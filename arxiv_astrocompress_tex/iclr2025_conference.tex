% \begin{document}
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% BEGIN added by Yibo
% \usepackage{xcolor}
\newcommand{\YY}[1]{{\color{brown} [YY: #1]}}
\newcommand{\JW}[1]{{\color{blue} [JW: #1]}}
\newcommand{\NEW}[1]{{\color{purple} [#1]}}
\newcommand\eat[1]{}
% make links colorful
\usepackage[colorlinks,linkcolor={blue!50!black},citecolor={blue!50!black},urlcolor={blue!50!black}]{hyperref}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{bm}
\usepackage{multirow}
% END added by Yibo

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024
\usepackage[rightcaption]{sidecap}
\usepackage{caption}

\captionsetup[table]{skip=10pt}

\usepackage{tabularx}
%\usepackage[table,xcdraw]{xcolor}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{soul, CJK}
\usepackage[utf8]{inputenc}
\usepackage{xspace}
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{9} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{9}  % for normal
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\usepackage{listings}
% \usepackage{subfigure}
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}}
\lstnewenvironment{pyt}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}


\title{AstroCompress: \\A benchmark dataset for multi-purpose \\compression of astronomical imagery}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{%
  Tuan Truong\thanks{Equal contribution first authors. Correspondence to \texttt{tuannt2@uci.edu}, \texttt{rithwik@berkeley.edu}.} \\
  UC Irvine\\
  % \texttt{tuannt2@uci.edu} \\
  \And
  Rithwik Sudharsan\footnotemark[1] \\
  UC Berkeley\\
  % \texttt{rithwik@berkeley.edu} \\
  \And
  Yibo Yang\\
  UC Irvine\\
  % \texttt{yibo.yang@uci.edu} \\
  \And
  Peter Xiangyuan Ma\\
  UC Berkeley\\
  % \texttt{peter\_ma@berkeley.edu} \\
  \And
  Ruihan Yang\\
  UC Irvine\\
  % \texttt{ruihan.yang@uci.edu} \\
  \And
  Stephan Mandt\\
  UC Irvine\\
  % \texttt{mandt@uci.edu} \\
  \And
  Joshua S.\ Bloom\\
  UC Berkeley; LBNL\\
  % \texttt{joshbloom@berkeley.edu} \\
  %Pineapple-Blueberry University\\
  %City, State, ZIP \\
  %\texttt{six@eng.pineapple-blueberry.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
The site conditions that make astronomical observatories in space and on the ground so desirable---cold and dark---demand a physical remoteness that leads to limited data transmission capabilities. Such transmission limitations directly bottleneck the amount of data acquired and in an era of costly modern observatories, any improvements in lossless data compression has the potential scale to billions of dollars worth of additional science that can be accomplished on the same instrument. Traditional lossless methods for compressing astrophysical data are manually designed. Neural data compression, on the other hand, holds the promise of learning compression algorithms end-to-end from data and outperforming classical techniques by leveraging the unique spatial, temporal, and wavelength structures of astronomical images.
%
This paper introduces AstroCompress (\url{https://huggingface.co/AstroCompress}): a neural compression challenge for astrophysics data, featuring four new datasets (and one legacy dataset) with 16-bit unsigned integer imaging data in various modes: space-based, ground-based, multi-wavelength, and time-series imaging. We provide code to easily access the data and benchmark seven lossless compression methods  (three neural and four non-neural, including all practical state-of-the-art algorithms).
Our results on lossless compression indicate that lossless neural compression techniques can enhance data collection at observatories, and provide guidance on the adoption of neural compression in scientific applications. 
% YY{I'm commenting this out as it's non-essential and the abstract is already quite long} Though the scope of this paper is restricted to lossless compression, we also comment on the potential exploration of lossy compression methods in future studies.
\end{abstract}

\input{sections/intro.tex}
\input{sections/related.tex}
\input{sections/data.tex}
% \input{sections/methods.tex}
\input{sections/experiments.tex}
\input{sections/discussion.tex}
\input{sections/conclusion.tex}
% \input{supplementary}  % Move this to the end for the submission



%\section*{Limitations and Broader Impacts}

%Limitations of our dataset include a lack of spectroscopic data, radio astronomy data or floating-point data. In addition, we believe that the significant time delay in between our SDSS image exposures may not be representative of other optical telescopes that may do back-to-back exposures of the same region. Such a dataset may bring forth significant compression gains, the way we have shown for back-to-back infrared imaging via JWST frame differencing.

%Limitations of our neural codecs include the marginal gains seen in comparison with JPEG-XL, the relative difficulty of deploying these codecs, and their current lack of generalizability.

%By improving compression for astrophysics, we can make telescopes operationally more efficient as more data can be collected and transmitted. Since our algorithms are lossless, we do not foresee any negative consequences on scientific research or society.



%\section{Guidelines for NeurIPS datasets and benchmarks track}
%\url{https://neurips.cc/Conferences/2024/CallForDatasetsBenchmarks}
%SCOPE. This track welcomes all work on data-centric machine learning research (DMLR), covering ML datasets and benchmarks as well as algorithms, tools, methods, and analyses for working with ML data. This includes but is not limited to:
%\begin{itemize}
%    \item New datasets, or carefully and thoughtfully designed (collections of) datasets based on previously available data.
%    \item Data generators and reinforcement learning environments.
%    \item Data-centric AI methods and tools, e.g. to measure and improve data quality or utility, or studies in data-centric AI that bring important new insight.
%    \item Advanced practices in data collection and curation that are of general interest even if the data itself cannot be shared.
%    \item Frameworks for responsible dataset development, audits of existing datasets, identifying significant problems with existing datasets and their use
%    \item Benchmarks on new or existing datasets, as well as benchmarking tools.
%    \item In-depth analyses of machine learning challenges and competitions (by organizers and/or participants) that yield important new insight.
%    \item Systematic analyses of existing systems on novel datasets yielding important new insight.
    
%\end{itemize}

\newpage

\subsection*{Acknowledgements}
This research is based in part on observations made with the NASA/ESA Hubble Space Telescope obtained from the Space Telescope Science Institute, which is operated by the Association of Universities for Research in Astronomy, Inc., under NASA contract NAS 5–26555. HST data are released under the Creative Commons Attribution 4.0 International license. This work is also based in part on observations made with the NASA/ESA/CSA James Webb Space Telescope. The data were obtained from the Mikulski Archive for Space Telescopes at the Space Telescope Science Institute, which is operated by the Association of Universities for Research in Astronomy, Inc., under NASA contract NAS 5-03127 for JWST. This research has made use of the Keck Observatory Archive (KOA), which is operated by the W.M.\,Keck Observatory and the NASA Exoplanet Science Institute (NExScI), under contract with the National Aeronautics and Space Administration. Funding for SDSS-III was provided by the Alfred P.\ Sloan Foundation, the Participating Institutions, the National Science Foundation, and the U.S. Department of Energy Office of Science. The SDSS-III website is \url{http://www.sdss3.org/}. All SDSS data used herein are considered in the public domain. Data in GBI-16-2D-Legacy, curated and released to the public in FITS format by \citet{maireles2023efficient}, makes use of observations the Isaac Newton Group of Telescopes, from Las Cumbres Observatory global telescope network and from The Joan Oró Telescope (TJO). 

We would like to thank Justus Will for running additional baseline experiments for the camera-ready version. Stephan Mandt acknowledges support from the National Science Foundation (NSF) under an NSF CAREER Award IIS-2047418 and IIS-2007719, the NSF LEAP Center, by the Department of Energy under grant DE-SC0022331, the IARPA WRIVA program, the Hasso Plattner Research Center at UCI, the Chan Zuckerberg Initiative, and gifts from Qualcomm and Disney.



\subsection*{Reproducibility Statement}
Our experimental results rely on already published, publicly available compression models. In cases where the architecture was modified to be compatible with new data formats, we were explicit about the alterations described in Sec.~\ref{sec:experiments} and additional architecture and training details in the supplementary material Sec.~\ref{sec:protocol}. We have also released the code base used for experiments in Sec.~\ref{sec:protocol} along with the data sets in the abstract.


\bibliographystyle{iclr2025_conference}

\bibliography{references}

\newpage
\appendix
\input{supplementary}

\end{document}
